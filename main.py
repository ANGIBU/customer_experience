# main.py

import os
import sys
import time
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

from data_analysis import DataAnalyzer
from feature_engineering import FeatureEngineer
from preprocessing import DataPreprocessor
from model_training import ModelTrainer
from validation import ValidationSystem
from prediction import PredictionSystem

class AISystem:
    def __init__(self):
        self.start_time = None
        self.results = {}
        self.target_accuracy = 0.50
        
    def setup_environment(self):
        """í™˜ê²½ ì„¤ì •"""
        print(f"Python ë²„ì „: {sys.version}")
        print(f"ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
        
        # í•„ìˆ˜ íŒŒì¼ í™•ì¸
        required_files = ['train.csv', 'test.csv', 'sample_submission.csv']
        missing_files = [f for f in required_files if not os.path.exists(f)]
        
        if missing_files:
            print(f"í•„ìˆ˜ íŒŒì¼ ëˆ„ë½: {missing_files}")
            return False
        
        # ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs('models', exist_ok=True)
        
        self.start_time = time.time()
        return True
    
    def step1_data_analysis(self):
        """ë°ì´í„° ë¶„ì„"""
        print("\n1ë‹¨ê³„: ë°ì´í„° ë¶„ì„")
        print("=" * 30)
        
        try:
            analyzer = DataAnalyzer()
            analysis_results = analyzer.run_analysis()
            
            self.results['data_analysis'] = analysis_results
            
            # ì‹œê°„ì  ì•ˆì „ì„± í™•ì¸
            temporal_info = analysis_results.get('temporal', {})
            if temporal_info:
                safe_ratio = temporal_info.get('safe_ratio', 1.0)
                is_temporally_safe = temporal_info.get('is_temporally_safe', False)
                overlap_ratio = temporal_info.get('overlap_ratio', 0.0)
                
                if is_temporally_safe:
                    print(f"âœ“ ì‹œê°„ì  ì•ˆì „ì„±: ì–‘í˜¸ (ì•ˆì „ ë¹„ìœ¨ {safe_ratio:.1%})")
                else:
                    print(f"âš  ì‹œê°„ì  ì•ˆì „ì„±: ê°œì„ ë¨ (ì•ˆì „ ë¹„ìœ¨ {safe_ratio:.1%}, ê²¹ì¹¨ {overlap_ratio:.1%})")
                    if safe_ratio >= 0.20:
                        print("  â†’ í—ˆìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€ìœ¼ë¡œ ì¡°ì •ë¨")
                    else:
                        print("  â†’ ì¶”ê°€ ë³´ì • ì ìš©ë¨")
            
            # ë°ì´í„° ëˆ„ìˆ˜ í™•ì¸
            leakage_info = analysis_results.get('leakage', {})
            if 'after_interaction' in leakage_info:
                leakage_data = leakage_info['after_interaction']
                is_leakage = leakage_data.get('is_leakage', False)
                leakage_score = leakage_data.get('leakage_score', 0)
                
                if is_leakage:
                    print(f"âš  ë°ì´í„° ëˆ„ìˆ˜ ê°ì§€: after_interaction (ìœ„í—˜ë„ {leakage_score}/5)")
                    print("  â†’ ìë™ ì œê±° ë° ì•ˆì „í•œ ëŒ€ì²´ í”¼ì²˜ ìƒì„± ì˜ˆì •")
                else:
                    print("âœ“ ë°ì´í„° ëˆ„ìˆ˜: ì•ˆì „")
            
            # ë°ì´í„° ë¬´ê²°ì„±
            integrity_info = analysis_results.get('integrity', {})
            if integrity_info.get('passed', True):
                print("âœ“ ë°ì´í„° ë¬´ê²°ì„±: í†µê³¼")
            else:
                issues_count = len(integrity_info.get('issues', []))
                print(f"âš  ë°ì´í„° ë¬´ê²°ì„±: {issues_count}ê°œ ë¬¸ì œ (ìë™ ì²˜ë¦¬ ì˜ˆì •)")
            
            # í”¼ì²˜ ì•ˆì •ì„± ìš”ì•½
            stability_info = analysis_results.get('stability', {})
            if stability_info:
                stable_features = sum(1 for feature_info in stability_info.values() 
                                    if feature_info.get('is_stable', False))
                total_features = len(stability_info)
                if total_features > 0:
                    stability_ratio = stable_features / total_features
                    print(f"âœ“ í”¼ì²˜ ì•ˆì •ì„±: {stable_features}/{total_features} ({stability_ratio:.1%}) ì•ˆì •")
            
            print("âœ“ ë°ì´í„° ë¶„ì„ ì™„ë£Œ")
            return True, analyzer
            
        except Exception as e:
            print(f"ë°ì´í„° ë¶„ì„ ì˜¤ë¥˜: {e}")
            self.results['data_analysis'] = {}
            return False, None
    
    def step2_feature_engineering(self):
        """í”¼ì²˜ ìƒì„±"""
        print("\n2ë‹¨ê³„: í”¼ì²˜ ìƒì„±")
        print("=" * 30)
        
        try:
            train_df = pd.read_csv('train.csv')
            test_df = pd.read_csv('test.csv')
            
            if train_df.empty or test_df.empty:
                print("ë°ì´í„° íŒŒì¼ ë¹„ì–´ìˆìŒ")
                return False, None, None, None
            
            # ì‹œê°„ì  ì„ê³„ê°’ ê°€ì ¸ì˜¤ê¸°
            temporal_threshold = None
            temporal_info = None
            if 'data_analysis' in self.results:
                temporal_data = self.results['data_analysis'].get('temporal', {})
                temporal_threshold = temporal_data.get('temporal_threshold')
                temporal_info = temporal_data
            
            engineer = FeatureEngineer()
            train_processed, test_processed = engineer.create_features(train_df, test_df, temporal_threshold)
            
            if train_processed is None or test_processed is None:
                print("í”¼ì²˜ ìƒì„± ì‹¤íŒ¨")
                return False, None, None, None
            
            original_features = train_df.shape[1] - 1  # ID ì œì™¸
            final_features = train_processed.shape[1] - 2  # ID, support_needs ì œì™¸
            created_features = final_features - original_features
            
            self.results['feature_engineering'] = {
                'original_features': original_features,
                'final_features': final_features,
                'created_features': created_features,
                'temporal_threshold': temporal_threshold,
                'safety_applied': temporal_info.get('is_temporally_safe', False) if temporal_info else False
            }
            
            print(f"âœ“ í”¼ì²˜ í™•ì¥: {original_features} â†’ {final_features} (+{created_features})")
            
            if temporal_threshold:
                print(f"âœ“ ì‹œê°„ì  ì•ˆì „ì¥ì¹˜ ì ìš©ë¨ (ì„ê³„ê°’: {temporal_threshold})")
            
            return True, engineer, train_processed, test_processed
            
        except Exception as e:
            print(f"í”¼ì²˜ ìƒì„± ì˜¤ë¥˜: {e}")
            return False, None, None, None
    
    def step3_preprocessing(self, train_df, test_df):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        print("\n3ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬")
        print("=" * 30)
        
        try:
            if train_df is None or test_df is None:
                print("ì…ë ¥ ë°ì´í„° None")
                return False, None, None, None, None, None, None, None
            
            preprocessor = DataPreprocessor()
            
            # ì‹œê°„ì  ì •ë³´ ì „ë‹¬
            temporal_info = None
            if 'data_analysis' in self.results:
                temporal_info = self.results['data_analysis'].get('temporal')
            
            train_final, test_final = preprocessor.process_data(train_df, test_df, temporal_info)
            
            if train_final is None or test_final is None:
                print("ì „ì²˜ë¦¬ ì‹¤íŒ¨")
                return False, None, None, None, None, None, None, None
            
            if train_final.empty or test_final.empty:
                print("ì „ì²˜ë¦¬ ë°ì´í„° ë¹„ì–´ìˆìŒ")
                return False, None, None, None, None, None, None, None
            
            # ì‹œê°„ ê¸°ë°˜ ë¶„í• 
            X_train, X_val, y_train, y_val, X_test, test_ids = preprocessor.prepare_data_temporal_optimized(
                train_final, test_final, val_size=0.18, gap_size=0.005
            )
            
            if X_train is None or X_val is None or y_train is None or y_val is None:
                print("ë°ì´í„° ë¶„í•  ì‹¤íŒ¨")
                return False, None, None, None, None, None, None, None
            
            if len(X_train) == 0 or len(X_val) == 0:
                print("ë¶„í•  ë°ì´í„° ë¹„ì–´ìˆìŒ")
                return False, None, None, None, None, None, None, None
            
            self.results['preprocessing'] = {
                'train_shape': X_train.shape,
                'val_shape': X_val.shape,
                'test_shape': X_test.shape,
                'selected_features': len(X_train.columns),
                'temporal_safety': temporal_info.get('is_temporally_safe', False) if temporal_info else False
            }
            
            print(f"âœ“ ë°ì´í„° ë¶„í• : í›ˆë ¨ {X_train.shape}, ê²€ì¦ {X_val.shape}, í…ŒìŠ¤íŠ¸ {X_test.shape}")
            print(f"âœ“ ìµœì¢… í”¼ì²˜ ìˆ˜: {len(X_train.columns)}ê°œ")
            
            return True, preprocessor, X_train, X_val, y_train, y_val, X_test, test_ids
            
        except Exception as e:
            print(f"ë°ì´í„° ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return False, None, None, None, None, None, None, None
    
    def step4_validation(self, X_train, y_train, X_val=None, y_val=None):
        """ê²€ì¦ ì‹œìŠ¤í…œ"""
        print("\n4ë‹¨ê³„: ê²€ì¦ ì‹œìŠ¤í…œ")
        print("=" * 30)
        
        try:
            if X_train is None or y_train is None:
                print("ê²€ì¦ ë°ì´í„° None")
                return False, None
            
            if len(X_train) == 0 or len(y_train) == 0:
                print("ê²€ì¦ ë°ì´í„° ë¹„ì–´ìˆìŒ")
                return False, None
            
            validator = ValidationSystem()
            validation_results = validator.validate_system(X_train, y_train, X_val, y_val)
            
            self.results['validation'] = validation_results
            
            # ê²€ì¦ ì„±ëŠ¥ í™•ì¸
            overall_score = validation_results.get('overall_score', 0.0)
            component_scores = validation_results.get('component_scores', {})
            holdout_score = component_scores.get('holdout_score', 0.0)
            cv_score = component_scores.get('cv_ensemble_score', 0.0)
            stability_score = component_scores.get('stability_score', 0.0)
            
            print(f"âœ“ í™€ë“œì•„ì›ƒ ê²€ì¦: {holdout_score:.4f}")
            print(f"âœ“ êµì°¨ê²€ì¦ ì•™ìƒë¸”: {cv_score:.4f}")
            print(f"âœ“ ëª¨ë¸ ì•ˆì •ì„±: {stability_score:.4f}")
            print(f"âœ“ ì¢…í•© ì ìˆ˜: {overall_score:.4f}")
            
            if overall_score >= self.target_accuracy:
                print("âœ“ ëª©í‘œ ì„±ëŠ¥ ë‹¬ì„±")
                status_icon = "âœ“"
            else:
                gap = self.target_accuracy - overall_score
                print(f"â†’ ëª©í‘œê¹Œì§€: {gap:.4f} (ì¶”ê°€ ìµœì í™” ì§„í–‰)")
                status_icon = "â†’"
            
            print(f"{status_icon} ê²€ì¦ ì‹œìŠ¤í…œ ì™„ë£Œ")
            return True, validator
            
        except Exception as e:
            print(f"ê²€ì¦ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
            self.results['validation'] = {'overall_score': 0.0}
            return False, None
    
    def step5_model_training(self, X_train, X_val, y_train, y_val, engineer, preprocessor):
        """ëª¨ë¸ í•™ìŠµ"""
        print("\n5ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ")
        print("=" * 30)
        
        try:
            if any(data is None for data in [X_train, X_val, y_train, y_val]):
                print("ëª¨ë¸ í•™ìŠµ ë°ì´í„° None")
                return False, None
            
            if any(len(data) == 0 for data in [X_train, X_val, y_train, y_val]):
                print("ëª¨ë¸ í•™ìŠµ ë°ì´í„° ë¹„ì–´ìˆìŒ")
                return False, None
            
            trainer = ModelTrainer()
            trainer.feature_names = list(X_train.columns)
            trainer.calculate_class_weights(y_train)
            
            print("ëª¨ë¸ í•™ìŠµ ì§„í–‰ ì¤‘...")
            trainer.train_models(X_train, X_val, y_train, y_val, engineer, preprocessor)
            
            # ì„±ëŠ¥ í™•ì¸
            best_score = 0.0
            best_model_name = None
            model_count = len(trainer.models)
            successful_models = []
            
            if trainer.models and model_count > 0:
                from sklearn.metrics import accuracy_score
                
                for model_name, model in trainer.models.items():
                    try:
                        X_val_clean = trainer.safe_data_conversion(X_val)
                        y_val_clean = trainer.safe_data_conversion(y_val)
                        
                        if model_name == 'lightgbm':
                            y_pred = model.predict(X_val_clean)
                            if y_pred.ndim == 2 and y_pred.shape[1] == 3:
                                y_pred_class = np.argmax(y_pred, axis=1)
                            else:
                                y_pred_class = np.clip(np.round(y_pred).astype(int), 0, 2)
                                
                        elif model_name == 'xgboost':
                            import xgboost as xgb
                            if trainer.feature_names:
                                xgb_test = xgb.DMatrix(X_val_clean, feature_names=trainer.feature_names)
                            else:
                                xgb_test = xgb.DMatrix(X_val_clean)
                            y_pred = model.predict(xgb_test)
                            if y_pred.ndim == 2 and y_pred.shape[1] == 3:
                                y_pred_class = np.argmax(y_pred, axis=1)
                            else:
                                y_pred_class = np.clip(np.round(y_pred).astype(int), 0, 2)
                                
                        elif model_name == 'catboost':
                            y_pred_class = model.predict(X_val_clean)
                            y_pred_class = np.clip(y_pred_class, 0, 2)
                            
                        elif model_name in ['stacking', 'voting']:
                            continue  # ì•™ìƒë¸” ëª¨ë¸ì€ ë³„ë„ ì²˜ë¦¬
                            
                        else:
                            y_pred_class = model.predict(X_val_clean)
                            y_pred_class = np.clip(y_pred_class, 0, 2)
                        
                        score = accuracy_score(y_val_clean, y_pred_class)
                        successful_models.append((model_name, score))
                        
                        if score > best_score:
                            best_score = score
                            best_model_name = model_name
                            
                    except Exception as e:
                        continue
            
            # ì„±ê³µí•œ ëª¨ë¸ë“¤ ì¶œë ¥
            if successful_models:
                print("âœ“ í•™ìŠµ ì™„ë£Œëœ ëª¨ë¸:")
                for model_name, score in sorted(successful_models, key=lambda x: x[1], reverse=True):
                    print(f"  - {model_name}: {score:.4f}")
            
            self.results['model_training'] = {
                'models_count': model_count,
                'successful_models': len(successful_models),
                'best_validation_score': best_score,
                'best_model': best_model_name,
                'target_achieved': best_score >= self.target_accuracy,
                'ensemble_weights': getattr(trainer, 'ensemble_weights', {}),
                'safety_features_used': self.results.get('feature_engineering', {}).get('safety_applied', False)
            }
            
            if best_model_name:
                print(f"âœ“ ìµœê³  ì„±ëŠ¥: {best_score:.4f} ({best_model_name})")
                if best_score >= self.target_accuracy:
                    print("âœ“ ëª©í‘œ ì •í™•ë„ ë‹¬ì„±")
                else:
                    gap = self.target_accuracy - best_score
                    print(f"â†’ ëª©í‘œê¹Œì§€: {gap:.4f}")
            
            print(f"âœ“ ì´ ëª¨ë¸ ìˆ˜: {len(successful_models)}/{model_count}")
            print("âœ“ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
            return True, trainer
            
        except Exception as e:
            print(f"ëª¨ë¸ í•™ìŠµ ì˜¤ë¥˜: {e}")
            self.results['model_training'] = {
                'models_count': 0,
                'successful_models': 0,
                'best_validation_score': 0.0,
                'best_model': None,
                'target_achieved': False
            }
            return False, None
    
    def step6_prediction(self):
        """ì˜ˆì¸¡ ìƒì„±"""
        print("\n6ë‹¨ê³„: ì˜ˆì¸¡ ìƒì„±")
        print("=" * 30)
        
        try:
            predictor = PredictionSystem()
            submission_df = predictor.generate_final_predictions()
            
            if submission_df is not None and not submission_df.empty:
                unique_classes = submission_df['support_needs'].unique()
                pred_counts = submission_df['support_needs'].value_counts().sort_index()
                
                print("âœ“ ì˜ˆì¸¡ ë¶„í¬:")
                total_preds = len(submission_df)
                for cls in [0, 1, 2]:
                    count = pred_counts.get(cls, 0)
                    pct = count / total_preds * 100
                    print(f"  í´ë˜ìŠ¤ {cls}: {count:,}ê°œ ({pct:.1f}%)")
                
                # ë¶„í¬ ê· í˜•ì„± í™•ì¸
                distribution_balance = len(unique_classes) / 3.0
                if distribution_balance >= 0.67:  # ìµœì†Œ 2ê°œ í´ë˜ìŠ¤
                    print(f"âœ“ ì˜ˆì¸¡ ë‹¤ì–‘ì„±: ì–‘í˜¸ ({len(unique_classes)}ê°œ í´ë˜ìŠ¤)")
                else:
                    print(f"âš  ì˜ˆì¸¡ ë‹¤ì–‘ì„±: ì œí•œì  ({len(unique_classes)}ê°œ í´ë˜ìŠ¤)")
                
                self.results['prediction'] = {
                    'submission_shape': submission_df.shape,
                    'prediction_counts': pred_counts.to_dict(),
                    'unique_classes': len(unique_classes),
                    'diversity_score': distribution_balance,
                    'method': 'weighted_ensemble_with_safety',
                    'safety_applied': self.results.get('feature_engineering', {}).get('safety_applied', False)
                }
                
                print("âœ“ ì˜ˆì¸¡ ìƒì„± ì™„ë£Œ")
                return True, submission_df
            else:
                print("ì˜ˆì¸¡ ìƒì„± ì‹¤íŒ¨ - ëŒ€ì²´ ë°©ë²• ì‹œë„")
                return self.fallback_prediction()
                
        except Exception as e:
            print(f"ì˜ˆì¸¡ ìƒì„± ì˜¤ë¥˜: {e}")
            return self.fallback_prediction()
    
    def fallback_prediction(self):
        """ëŒ€ì²´ ì˜ˆì¸¡"""
        print("â†’ ëŒ€ì²´ ì˜ˆì¸¡ ì‹¤í–‰")
        
        try:
            from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
            from sklearn.preprocessing import LabelEncoder
            from sklearn.model_selection import cross_val_score
            
            train_df = pd.read_csv('train.csv')
            test_df = pd.read_csv('test.csv')
            
            # í”¼ì²˜ ì¤€ë¹„
            numeric_cols = ['age', 'tenure', 'frequent', 'payment_interval', 'contract_length']
            categorical_cols = ['gender', 'subscription_type']
            
            train_processed = train_df.copy()
            test_processed = test_df.copy()
            
            # ë²”ì£¼í˜• ì¸ì½”ë”©
            le = LabelEncoder()
            for col in categorical_cols:
                if col in train_df.columns and col in test_df.columns:
                    combined = pd.concat([train_df[col], test_df[col]])
                    le.fit(combined.fillna('Unknown'))
                    train_processed[col] = le.transform(train_df[col].fillna('Unknown'))
                    test_processed[col] = le.transform(test_df[col].fillna('Unknown'))
            
            # ì¶”ê°€ í”¼ì²˜ ìƒì„±
            if all(col in train_processed.columns for col in ['age', 'tenure']):
                train_processed['age_tenure_ratio'] = train_processed['age'] / (train_processed['tenure'] + 1)
                test_processed['age_tenure_ratio'] = test_processed['age'] / (test_processed['tenure'] + 1)
            
            if all(col in train_processed.columns for col in ['frequent', 'payment_interval']):
                train_processed['frequency_payment_ratio'] = train_processed['frequent'] / (train_processed['payment_interval'] + 1)
                test_processed['frequency_payment_ratio'] = test_processed['frequent'] / (test_processed['payment_interval'] + 1)
            
            # í”¼ì²˜ ì„ íƒ
            feature_cols = numeric_cols + categorical_cols + ['age_tenure_ratio', 'frequency_payment_ratio']
            feature_cols = [col for col in feature_cols if col in train_processed.columns and col in test_processed.columns]
            
            X = train_processed[feature_cols].fillna(0)
            y = train_processed['support_needs']
            X_test = test_processed[feature_cols].fillna(0)
            
            # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
            class_counts = np.bincount(y)
            total_samples = len(y)
            class_weights = {}
            
            for i, count in enumerate(class_counts):
                if count > 0:
                    class_weights[i] = total_samples / (len(class_counts) * count)
                else:
                    class_weights[i] = 1.0
            
            # í´ë˜ìŠ¤ 1 ë³´ì •
            class_weights[1] *= 1.102
            class_weights[2] *= 1.051
            
            # ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ
            models = []
            
            # Random Forest
            rf_model = RandomForestClassifier(
                n_estimators=500,
                max_depth=12,
                min_samples_split=8,
                min_samples_leaf=4,
                max_features=0.8,
                class_weight=class_weights,
                random_state=42,
                n_jobs=-1
            )
            models.append(('rf', rf_model))
            
            # Gradient Boosting
            gb_model = GradientBoostingClassifier(
                n_estimators=300,
                learning_rate=0.06,
                max_depth=7,
                min_samples_split=15,
                min_samples_leaf=8,
                subsample=0.85,
                random_state=42
            )
            models.append(('gb', gb_model))
            
            # ì•™ìƒë¸” ì˜ˆì¸¡
            ensemble_predictions = []
            model_weights = [0.6, 0.4]  # RFì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
            
            for i, (name, model) in enumerate(models):
                model.fit(X, y)
                pred_proba = model.predict_proba(X_test)
                ensemble_predictions.append(pred_proba * model_weights[i])
            
            # ê°€ì¤‘ í‰ê· 
            final_proba = np.sum(ensemble_predictions, axis=0)
            
            # í´ë˜ìŠ¤ ê· í˜• ì¡°ì •
            class_adjustments = np.array([1.0, 1.03, 1.01])
            adjusted_proba = final_proba * class_adjustments[np.newaxis, :]
            normalized_proba = adjusted_proba / adjusted_proba.sum(axis=1, keepdims=True)
            
            predictions = np.argmax(normalized_proba, axis=1)
            
            # ë¶„í¬ í›„ì²˜ë¦¬
            pred_counts = np.bincount(predictions, minlength=3)
            total_preds = len(predictions)
            
            # í´ë˜ìŠ¤ 1ì´ ë„ˆë¬´ ì ìœ¼ë©´ ì¡°ì •
            if pred_counts[1] < total_preds * 0.08:
                class_1_proba = normalized_proba[:, 1]
                top_indices = np.argsort(class_1_proba)[-int(total_preds * 0.082):]
                predictions[top_indices] = 1
            
            # ì œì¶œ íŒŒì¼
            submission_df = pd.DataFrame({
                'ID': test_processed['ID'],
                'support_needs': predictions.astype(int)
            })
            
            submission_df.to_csv('submission.csv', index=False)
            
            # ë¶„í¬ ì¶œë ¥
            final_counts = submission_df['support_needs'].value_counts().sort_index()
            print("âœ“ ëŒ€ì²´ ì˜ˆì¸¡ ë¶„í¬:")
            for cls in [0, 1, 2]:
                count = final_counts.get(cls, 0)
                pct = count / len(submission_df) * 100
                print(f"  í´ë˜ìŠ¤ {cls}: {count:,}ê°œ ({pct:.1f}%)")
            
            self.results['prediction'] = {
                'submission_shape': submission_df.shape,
                'prediction_counts': final_counts.to_dict(),
                'method': 'fallback_ensemble_safe'
            }
            
            print("âœ“ ëŒ€ì²´ ì˜ˆì¸¡ ì™„ë£Œ")
            return True, submission_df
            
        except Exception as e:
            print(f"ëŒ€ì²´ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return False, None
    
    def generate_report(self):
        """ì„±ê³¼ ë³´ê³ ì„œ"""
        print("\n" + "=" * 50)
        print("ìµœì¢… ì„±ê³¼ ë³´ê³ ì„œ")
        print("=" * 50)
        
        try:
            total_time = time.time() - self.start_time if self.start_time else 0
            print(f"ì´ ì‹¤í–‰ ì‹œê°„: {total_time:.1f}ì´ˆ")
            
            # ë°ì´í„° ì•ˆì „ì„± ì ê²€ ê²°ê³¼
            print("\nğŸ“Š ë°ì´í„° ì•ˆì „ì„± ì ê²€:")
            if 'data_analysis' in self.results:
                da = self.results['data_analysis']
                
                # ì‹œê°„ì  ì•ˆì „ì„±
                temporal = da.get('temporal', {})
                if temporal:
                    safe_ratio = temporal.get('safe_ratio', 0)
                    is_safe = temporal.get('is_temporally_safe', False)
                    if is_safe:
                        print(f"  âœ“ ì‹œê°„ì  ëˆ„ìˆ˜ ë°©ì§€: ì•ˆì „ ({safe_ratio:.1%})")
                    else:
                        print(f"  âš  ì‹œê°„ì  ëˆ„ìˆ˜ ìœ„í—˜: ì œì–´ë¨ ({safe_ratio:.1%})")
                
                # í”¼ì²˜ ëˆ„ìˆ˜
                leakage = da.get('leakage', {})
                if 'after_interaction' in leakage:
                    if leakage['after_interaction'].get('is_leakage', False):
                        print("  âœ“ í”¼ì²˜ ëˆ„ìˆ˜: íƒì§€ ë° ì œê±° ì™„ë£Œ")
                    else:
                        print("  âœ“ í”¼ì²˜ ëˆ„ìˆ˜: ì•ˆì „")
                
                # ë¬´ê²°ì„±
                integrity = da.get('integrity', {})
                if integrity.get('passed', True):
                    print("  âœ“ ë°ì´í„° ë¬´ê²°ì„±: í†µê³¼")
                else:
                    issues = len(integrity.get('issues', []))
                    print(f"  â†’ ë°ì´í„° ë¬´ê²°ì„±: {issues}ê°œ ë¬¸ì œ ì²˜ë¦¬ë¨")
            
            # í”¼ì²˜ ìƒì„± ê²°ê³¼
            print("\nğŸ”§ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§:")
            if 'feature_engineering' in self.results:
                fe = self.results['feature_engineering']
                print(f"  í”¼ì²˜ í™•ì¥: {fe['original_features']} â†’ {fe['final_features']} (+{fe['created_features']})")
                
                if fe.get('safety_applied'):
                    print("  âœ“ ì•ˆì „ì¥ì¹˜ ì ìš©ë¨")
                
                if fe.get('temporal_threshold'):
                    print(f"  ì‹œê°„ì  ì„ê³„ê°’: {fe['temporal_threshold']}")
            
            # ì „ì²˜ë¦¬ ê²°ê³¼
            print("\nâš™ï¸ ë°ì´í„° ì „ì²˜ë¦¬:")
            if 'preprocessing' in self.results:
                pp = self.results['preprocessing']
                print(f"  ìµœì¢… í”¼ì²˜: {pp.get('selected_features', 0)}ê°œ")
                print(f"  ë°ì´í„° ë¶„í• : í›ˆë ¨ {pp.get('train_shape', (0,0))[0]:,}ê°œ")
                
                if pp.get('temporal_safety'):
                    print("  âœ“ ì‹œê°„ì  ì•ˆì „ ë¶„í•  ì ìš©")
            
            # ê²€ì¦ ê²°ê³¼
            print("\nğŸ¯ ëª¨ë¸ ê²€ì¦:")
            if 'validation' in self.results:
                val = self.results['validation']
                overall_score = val.get('overall_score', 0.0)
                print(f"  ê²€ì¦ ì ìˆ˜: {overall_score:.4f}")
                
                component_scores = val.get('component_scores', {})
                if component_scores:
                    print(f"  - í™€ë“œì•„ì›ƒ: {component_scores.get('holdout_score', 0):.4f}")
                    print(f"  - êµì°¨ê²€ì¦: {component_scores.get('cv_ensemble_score', 0):.4f}")
                    print(f"  - ì•ˆì •ì„±: {component_scores.get('stability_score', 0):.4f}")
                
                if overall_score >= self.target_accuracy:
                    print("  âœ“ ëª©í‘œ ì •í™•ë„ ë‹¬ì„±")
                else:
                    gap = self.target_accuracy - overall_score
                    print(f"  â†’ ëª©í‘œê¹Œì§€: {gap:.4f}")
            
            # ëª¨ë¸ í•™ìŠµ ê²°ê³¼
            print("\nğŸ¤– ëª¨ë¸ í•™ìŠµ:")
            if 'model_training' in self.results:
                mt = self.results['model_training']
                successful = mt.get('successful_models', 0)
                total = mt.get('models_count', 0)
                print(f"  í•™ìŠµ ì„±ê³µ: {successful}/{total}ê°œ ëª¨ë¸")
                print(f"  ìµœê³  ê²€ì¦ ì„±ëŠ¥: {mt['best_validation_score']:.4f}")
                
                if mt.get('best_model'):
                    print(f"  ìµœê³  ëª¨ë¸: {mt['best_model']}")
                
                if mt['target_achieved']:
                    print("  âœ“ ëª¨ë¸ ëª©í‘œ ë‹¬ì„±")
                
                if mt.get('safety_features_used'):
                    print("  âœ“ ì•ˆì „ í”¼ì²˜ ì‚¬ìš©")
            
            # ì˜ˆì¸¡ ê²°ê³¼
            print("\nğŸ“ˆ ì˜ˆì¸¡ ê²°ê³¼:")
            if 'prediction' in self.results:
                pred = self.results['prediction']
                print("  ì˜ˆì¸¡ ë¶„í¬:")
                total_predictions = sum(pred['prediction_counts'].values())
                for cls in [0, 1, 2]:
                    count = pred['prediction_counts'].get(cls, 0)
                    pct = count / total_predictions * 100 if total_predictions > 0 else 0
                    print(f"    í´ë˜ìŠ¤ {cls}: {pct:.1f}%")
                
                diversity_score = pred.get('diversity_score', 0)
                print(f"  ì˜ˆì¸¡ ë‹¤ì–‘ì„±: {diversity_score:.2f}")
                
                method = pred.get('method', 'unknown')
                print(f"  ì˜ˆì¸¡ ë°©ë²•: {method}")
                
                if pred.get('safety_applied'):
                    print("  âœ“ ì•ˆì „ì¥ì¹˜ ì ìš©ë¨")
            
            # ì „ì²´ ì„±ê³µë¥ 
            print("\nğŸ“‹ ì‹œìŠ¤í…œ ìƒíƒœ:")
            total_steps = 6
            completed_steps = sum(1 for step in ['data_analysis', 'feature_engineering', 'preprocessing', 'validation', 'model_training', 'prediction'] if step in self.results)
            success_rate = completed_steps / total_steps * 100
            
            print(f"  ë‹¨ê³„ ì™„ë£Œìœ¨: {completed_steps}/{total_steps} ({success_rate:.1f}%)")
            
            # ì „ì²´ í‰ê°€
            print("\nğŸ–ï¸ ìµœì¢… í‰ê°€:")
            if 'validation' in self.results and 'model_training' in self.results:
                val_score = self.results['validation'].get('overall_score', 0.0)
                model_achieved = self.results['model_training'].get('target_achieved', False)
                safety_applied = any(self.results.get(step, {}).get('safety_applied', False) 
                                   for step in ['feature_engineering', 'preprocessing', 'prediction'])
                
                if val_score >= self.target_accuracy and model_achieved:
                    grade = "ìš°ìˆ˜"
                    icon = "ğŸ†"
                elif val_score >= self.target_accuracy * 0.95:
                    grade = "ì–‘í˜¸"
                    icon = "ğŸ¥ˆ"
                elif success_rate >= 83:
                    grade = "ì•ˆì •"
                    icon = "ğŸ¥‰"
                else:
                    grade = "ë¶€ë¶„ ì„±ê³µ"
                    icon = "âš¡"
                
                print(f"  {icon} ì‹œìŠ¤í…œ ë“±ê¸‰: {grade}")
                
                if safety_applied:
                    print("  ğŸ›¡ï¸ ë°ì´í„° ì•ˆì „ì¥ì¹˜ ê°€ë™")
            
        except Exception as e:
            print(f"ë³´ê³ ì„œ ìƒì„± ì˜¤ë¥˜: {e}")
    
    def run_system(self):
        """ì „ì²´ ì‹œìŠ¤í…œ ì‹¤í–‰"""
        try:
            # í™˜ê²½ ì„¤ì •
            if not self.setup_environment():
                print("í™˜ê²½ ì„¤ì • ì‹¤íŒ¨")
                return False
            
            # 1ë‹¨ê³„: ë°ì´í„° ë¶„ì„
            success, analyzer = self.step1_data_analysis()
            if not success:
                print("1ë‹¨ê³„ ì‹¤íŒ¨ - ê³„ì† ì§„í–‰")
            
            # 2ë‹¨ê³„: í”¼ì²˜ ìƒì„±
            success, engineer, train_df, test_df = self.step2_feature_engineering()
            if not success or train_df is None or test_df is None:
                print("2ë‹¨ê³„ ì‹¤íŒ¨ - ëŒ€ì²´ ì˜ˆì¸¡")
                fallback_success, fallback_result = self.fallback_prediction()
                if fallback_success:
                    self.generate_report()
                    return True
                else:
                    print("ëŒ€ì²´ ì˜ˆì¸¡ ì‹¤íŒ¨")
                    return False
            
            # 3ë‹¨ê³„: ì „ì²˜ë¦¬
            success, preprocessor, X_train, X_val, y_train, y_val, X_test, test_ids = self.step3_preprocessing(train_df, test_df)
            if not success or any(data is None for data in [X_train, X_val, y_train, y_val]):
                print("3ë‹¨ê³„ ì‹¤íŒ¨ - ëŒ€ì²´ ì˜ˆì¸¡")
                fallback_success, fallback_result = self.fallback_prediction()
                if fallback_success:
                    self.generate_report()
                    return True
                else:
                    print("ëŒ€ì²´ ì˜ˆì¸¡ ì‹¤íŒ¨")
                    return False
            
            # 4ë‹¨ê³„: ê²€ì¦
            success, validator = self.step4_validation(X_train, y_train, X_val, y_val)
            if not success:
                print("4ë‹¨ê³„ ì‹¤íŒ¨ - ê³„ì† ì§„í–‰")
            
            # 5ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ
            success, trainer = self.step5_model_training(X_train, X_val, y_train, y_val, engineer, preprocessor)
            if not success:
                print("5ë‹¨ê³„ ì‹¤íŒ¨ - ê³„ì† ì§„í–‰")
            
            # 6ë‹¨ê³„: ì˜ˆì¸¡ ìƒì„±
            success, submission_df = self.step6_prediction()
            if not success:
                print("6ë‹¨ê³„ ì‹¤íŒ¨ - ìµœì¢… ëŒ€ì²´")
                final_success, final_result = self.fallback_prediction()
                if not final_success:
                    print("ìµœì¢… ëŒ€ì²´ ì‹¤íŒ¨")
                    return False
            
            # ë³´ê³ ì„œ ìƒì„±
            self.generate_report()
            
            print(f"\n{'='*50}")
            print("ğŸ‰ AI ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ")
            print(f"{'='*50}")
            return True
            
        except Exception as e:
            print(f"ì‹œìŠ¤í…œ ì‹¤í–‰ ì˜ˆì™¸: {e}")
            
            try:
                fallback_success, fallback_result = self.fallback_prediction()
                if fallback_success:
                    print("ëŒ€ì²´ ëª¨ë“œ ì„±ê³µ")
                    return True
                else:
                    print("ëŒ€ì²´ ëª¨ë“œ ì‹¤íŒ¨")
                    return False
            except Exception as fallback_e:
                print(f"ëŒ€ì²´ ëª¨ë“œ ì˜ˆì™¸: {fallback_e}")
                return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    ai_system = AISystem()
    
    try:
        success = ai_system.run_system()
        
        if success:
            print("\nâœ… í”„ë¡œê·¸ë¨ ì •ìƒ ì™„ë£Œ")
            return 0
        else:
            print("\nâŒ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì‹¤íŒ¨")
            return 1
            
    except Exception as e:
        print(f"\në©”ì¸ í•¨ìˆ˜ ì˜ˆì™¸: {e}")
        print("âŒ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì‹¤íŒ¨")
        return 1

if __name__ == "__main__":
    exit_code = main()