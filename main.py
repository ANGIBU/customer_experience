# main.py

import os
import sys
import time
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

from data_analysis import DataAnalyzer
from feature_engineering import FeatureEngineer
from preprocessing import DataPreprocessor
from model_training import ModelTrainer
from validation import ValidationSystem
from prediction import PredictionSystem

class AISystem:
    def __init__(self):
        self.start_time = None
        self.results = {}
        self.target_accuracy = 0.50
        
    def setup_environment(self):
        """í™˜ê²½ ì„¤ì •"""
        print(f"Python ë²„ì „: {sys.version}")
        print(f"ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
        
        # í•„ìˆ˜ íŒŒì¼ í™•ì¸
        required_files = ['train.csv', 'test.csv', 'sample_submission.csv']
        missing_files = [f for f in required_files if not os.path.exists(f)]
        
        if missing_files:
            print(f"í•„ìˆ˜ íŒŒì¼ ëˆ„ë½: {missing_files}")
            return False
        
        # ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs('models', exist_ok=True)
        
        self.start_time = time.time()
        return True
    
    def step1_data_analysis(self):
        """ë°ì´í„° ë¶„ì„"""
        print("\n1ë‹¨ê³„: ë°ì´í„° ë¶„ì„")
        print("=" * 30)
        
        try:
            analyzer = DataAnalyzer()
            analysis_results = analyzer.run_analysis()
            
            self.results['data_analysis'] = analysis_results
            
            # ì‹œê°„ì  ì•ˆì „ì„± í™•ì¸
            temporal_info = analysis_results.get('temporal', {})
            if temporal_info:
                safe_ratio = temporal_info.get('safe_ratio', 1.0)
                is_temporally_safe = temporal_info.get('is_temporally_safe', False)
                overlap_ratio = temporal_info.get('overlap_ratio', 0.0)
                
                if is_temporally_safe:
                    print(f"âœ“ ì‹œê°„ì  ì•ˆì „ì„±: ìš°ìˆ˜ (ì•ˆì „ ë¹„ìœ¨ {safe_ratio:.1%})")
                else:
                    print(f"âš  ì‹œê°„ì  ëˆ„ìˆ˜ ìœ„í—˜: ì—„ê²©í•œ ë³´ì • ì ìš© (ì•ˆì „ ë¹„ìœ¨ {safe_ratio:.1%})")
                    if safe_ratio >= 0.30:
                        print("  â†’ í—ˆìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€ìœ¼ë¡œ ë³´ì •ë¨")
                    else:
                        print("  â†’ ê°•ë ¥í•œ ëˆ„ìˆ˜ ì°¨ë‹¨ ì ìš©")
            
            # ë°ì´í„° ëˆ„ìˆ˜ í™•ì¸
            leakage_info = analysis_results.get('leakage', {})
            if 'after_interaction' in leakage_info:
                leakage_data = leakage_info['after_interaction']
                is_leakage = leakage_data.get('is_leakage', False)
                leakage_score = leakage_data.get('leakage_score', 0)
                
                if is_leakage:
                    print(f"âš  ë°ì´í„° ëˆ„ìˆ˜ ê°ì§€: after_interaction ì™„ì „ ì œê±° (ìœ„í—˜ë„ {leakage_score}/5)")
                else:
                    print("âœ“ ë°ì´í„° ëˆ„ìˆ˜: ì•ˆì „")
            
            # ë°ì´í„° ë¬´ê²°ì„±
            integrity_info = analysis_results.get('integrity', {})
            if integrity_info.get('passed', True):
                print("âœ“ ë°ì´í„° ë¬´ê²°ì„±: í†µê³¼")
            else:
                issues_count = len(integrity_info.get('issues', []))
                print(f"âš  ë°ì´í„° ë¬´ê²°ì„±: {issues_count}ê°œ ë¬¸ì œ (ìë™ ì²˜ë¦¬)")
            
            print("âœ“ ë°ì´í„° ë¶„ì„ ì™„ë£Œ")
            return True, analyzer
            
        except Exception as e:
            print(f"ë°ì´í„° ë¶„ì„ ì˜¤ë¥˜: {e}")
            self.results['data_analysis'] = {}
            return False, None
    
    def step2_feature_engineering(self):
        """í”¼ì²˜ ìƒì„±"""
        print("\n2ë‹¨ê³„: í”¼ì²˜ ìƒì„±")
        print("=" * 30)
        
        try:
            train_df = pd.read_csv('train.csv')
            test_df = pd.read_csv('test.csv')
            
            if train_df.empty or test_df.empty:
                print("ë°ì´í„° íŒŒì¼ ë¹„ì–´ìˆìŒ")
                return False, None, None, None
            
            # ì‹œê°„ì  ì„ê³„ê°’ ê°€ì ¸ì˜¤ê¸°
            temporal_threshold = None
            temporal_info = None
            if 'data_analysis' in self.results:
                temporal_data = self.results['data_analysis'].get('temporal', {})
                temporal_threshold = temporal_data.get('temporal_threshold')
                temporal_info = temporal_data
            
            engineer = FeatureEngineer()
            train_processed, test_processed = engineer.create_features(train_df, test_df, temporal_threshold)
            
            if train_processed is None or test_processed is None:
                print("í”¼ì²˜ ìƒì„± ì‹¤íŒ¨")
                return False, None, None, None
            
            original_features = train_df.shape[1] - 1  # ID ì œì™¸
            final_features = train_processed.shape[1] - 2  # ID, support_needs ì œì™¸
            created_features = final_features - original_features
            
            self.results['feature_engineering'] = {
                'original_features': original_features,
                'final_features': final_features,
                'created_features': created_features,
                'temporal_threshold': temporal_threshold,
                'safety_applied': True
            }
            
            print(f"âœ“ í”¼ì²˜ í™•ì¥: {original_features} â†’ {final_features} (+{created_features})")
            print("âœ“ ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ ì™„ë£Œ")
            
            return True, engineer, train_processed, test_processed
            
        except Exception as e:
            print(f"í”¼ì²˜ ìƒì„± ì˜¤ë¥˜: {e}")
            return False, None, None, None
    
    def step3_preprocessing(self, train_df, test_df):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        print("\n3ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬")
        print("=" * 30)
        
        try:
            if train_df is None or test_df is None:
                print("ì…ë ¥ ë°ì´í„° None")
                return False, None, None, None, None, None, None, None
            
            preprocessor = DataPreprocessor()
            
            # ì‹œê°„ì  ì •ë³´ ì „ë‹¬
            temporal_info = None
            if 'data_analysis' in self.results:
                temporal_info = self.results['data_analysis'].get('temporal')
            
            train_final, test_final = preprocessor.process_data(train_df, test_df, temporal_info)
            
            if train_final is None or test_final is None:
                print("ì „ì²˜ë¦¬ ì‹¤íŒ¨")
                return False, None, None, None, None, None, None, None
            
            if train_final.empty or test_final.empty:
                print("ì „ì²˜ë¦¬ ë°ì´í„° ë¹„ì–´ìˆìŒ")
                return False, None, None, None, None, None, None, None
            
            # ë°ì´í„° ë¶„í• 
            X_train, X_val, y_train, y_val, X_test, test_ids = preprocessor.prepare_data_temporal_optimized(
                train_final, test_final, val_size=0.2, gap_size=0.01
            )
            
            if X_train is None or X_val is None or y_train is None or y_val is None:
                print("ë°ì´í„° ë¶„í•  ì‹¤íŒ¨")
                return False, None, None, None, None, None, None, None
            
            if len(X_train) == 0 or len(X_val) == 0:
                print("ë¶„í•  ë°ì´í„° ë¹„ì–´ìˆìŒ")
                return False, None, None, None, None, None, None, None
            
            self.results['preprocessing'] = {
                'train_shape': X_train.shape,
                'val_shape': X_val.shape,
                'test_shape': X_test.shape,
                'selected_features': len(X_train.columns),
                'temporal_safety': True
            }
            
            print(f"âœ“ ë°ì´í„° ë¶„í• : í›ˆë ¨ {X_train.shape}, ê²€ì¦ {X_val.shape}, í…ŒìŠ¤íŠ¸ {X_test.shape}")
            print(f"âœ“ ìµœì¢… í”¼ì²˜ ìˆ˜: {len(X_train.columns)}ê°œ")
            
            return True, preprocessor, X_train, X_val, y_train, y_val, X_test, test_ids
            
        except Exception as e:
            print(f"ë°ì´í„° ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return False, None, None, None, None, None, None, None
    
    def step4_validation(self, X_train, y_train, X_val=None, y_val=None):
        """ê²€ì¦ ì‹œìŠ¤í…œ"""
        print("\n4ë‹¨ê³„: ê²€ì¦ ì‹œìŠ¤í…œ")
        print("=" * 30)
        
        try:
            if X_train is None or y_train is None:
                print("ê²€ì¦ ë°ì´í„° None")
                return False, None
            
            if len(X_train) == 0 or len(y_train) == 0:
                print("ê²€ì¦ ë°ì´í„° ë¹„ì–´ìˆìŒ")
                return False, None
            
            validator = ValidationSystem()
            validation_results = validator.validate_system(X_train, y_train, X_val, y_val)
            
            self.results['validation'] = validation_results
            
            # ê²€ì¦ ì„±ëŠ¥ í™•ì¸
            overall_score = validation_results.get('overall_score', 0.0)
            component_scores = validation_results.get('component_scores', {})
            holdout_score = component_scores.get('holdout_score', 0.0)
            cv_score = component_scores.get('cv_ensemble_score', 0.0)
            stability_score = component_scores.get('stability_score', 0.0)
            
            print(f"âœ“ í™€ë“œì•„ì›ƒ ê²€ì¦: {holdout_score:.4f}")
            print(f"âœ“ êµì°¨ê²€ì¦ ì•™ìƒë¸”: {cv_score:.4f}")
            print(f"âœ“ ëª¨ë¸ ì•ˆì •ì„±: {stability_score:.4f}")
            print(f"âœ“ ì¢…í•© ì ìˆ˜: {overall_score:.4f}")
            
            if overall_score >= self.target_accuracy:
                print("âœ“ ëª©í‘œ ì„±ëŠ¥ ë‹¬ì„±")
                status_icon = "âœ“"
            else:
                gap = self.target_accuracy - overall_score
                print(f"â†’ ëª©í‘œê¹Œì§€: {gap:.4f}")
                status_icon = "â†’"
            
            print(f"{status_icon} ê²€ì¦ ì‹œìŠ¤í…œ ì™„ë£Œ")
            return True, validator
            
        except Exception as e:
            print(f"ê²€ì¦ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
            self.results['validation'] = {'overall_score': 0.0}
            return False, None
    
    def step5_model_training(self, X_train, X_val, y_train, y_val, engineer, preprocessor):
        """ëª¨ë¸ í•™ìŠµ"""
        print("\n5ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ")
        print("=" * 30)
        
        try:
            if any(data is None for data in [X_train, X_val, y_train, y_val]):
                print("ëª¨ë¸ í•™ìŠµ ë°ì´í„° None")
                return False, None
            
            if any(len(data) == 0 for data in [X_train, X_val, y_train, y_val]):
                print("ëª¨ë¸ í•™ìŠµ ë°ì´í„° ë¹„ì–´ìˆìŒ")
                return False, None
            
            trainer = ModelTrainer()
            trainer.feature_names = list(X_train.columns)
            trainer.calculate_class_weights(y_train)
            
            # ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
            results = trainer.train_models(X_train, X_val, y_train, y_val, engineer, preprocessor)
            
            # ì„±ëŠ¥ í™•ì¸
            best_score = 0.0
            best_model_name = None
            successful_models = []
            
            if results:
                for model_name, score in results.items():
                    if score > 0:
                        successful_models.append((model_name, score))
                        if score > best_score:
                            best_score = score
                            best_model_name = model_name
            
            self.results['model_training'] = {
                'models_count': len(trainer.models),
                'successful_models': len(successful_models),
                'best_validation_score': best_score,
                'best_model': best_model_name,
                'target_achieved': best_score >= self.target_accuracy,
                'ensemble_weights': trainer.ensemble_weights,
                'safety_features_used': True
            }
            
            if best_model_name:
                print(f"âœ“ ìµœê³  ì„±ëŠ¥: {best_score:.4f} ({best_model_name})")
                if best_score >= self.target_accuracy:
                    print("âœ“ ëª©í‘œ ì •í™•ë„ ë‹¬ì„±")
                else:
                    gap = self.target_accuracy - best_score
                    print(f"â†’ ëª©í‘œê¹Œì§€: {gap:.4f}")
            
            print(f"âœ“ ì„±ê³µ ëª¨ë¸: {len(successful_models)}ê°œ")
            print("âœ“ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
            return True, trainer
            
        except Exception as e:
            print(f"ëª¨ë¸ í•™ìŠµ ì˜¤ë¥˜: {e}")
            self.results['model_training'] = {
                'models_count': 0,
                'successful_models': 0,
                'best_validation_score': 0.0,
                'best_model': None,
                'target_achieved': False
            }
            return False, None
    
    def step6_prediction(self):
        """ì˜ˆì¸¡ ìƒì„±"""
        print("\n6ë‹¨ê³„: ì˜ˆì¸¡ ìƒì„±")
        print("=" * 30)
        
        try:
            predictor = PredictionSystem()
            submission_df = predictor.generate_final_predictions()
            
            if submission_df is not None and not submission_df.empty:
                unique_classes = submission_df['support_needs'].unique()
                pred_counts = submission_df['support_needs'].value_counts().sort_index()
                
                print("âœ“ ì˜ˆì¸¡ ë¶„í¬:")
                total_preds = len(submission_df)
                for cls in [0, 1, 2]:
                    count = pred_counts.get(cls, 0)
                    pct = count / total_preds * 100
                    print(f"  í´ë˜ìŠ¤ {cls}: {count:,}ê°œ ({pct:.1f}%)")
                
                # ë¶„í¬ ê· í˜•ì„± í™•ì¸
                distribution_balance = len(unique_classes) / 3.0
                if distribution_balance >= 0.67:
                    print(f"âœ“ ì˜ˆì¸¡ ë‹¤ì–‘ì„±: ìš°ìˆ˜ ({len(unique_classes)}ê°œ í´ë˜ìŠ¤)")
                else:
                    print(f"âš  ì˜ˆì¸¡ ë‹¤ì–‘ì„±: ì œí•œì  ({len(unique_classes)}ê°œ í´ë˜ìŠ¤)")
                
                self.results['prediction'] = {
                    'submission_shape': submission_df.shape,
                    'prediction_counts': pred_counts.to_dict(),
                    'unique_classes': len(unique_classes),
                    'diversity_score': distribution_balance,
                    'method': 'optimized_ensemble_safe',
                    'safety_applied': True
                }
                
                print("âœ“ ì˜ˆì¸¡ ìƒì„± ì™„ë£Œ")
                return True, submission_df
            else:
                print("ì˜ˆì¸¡ ìƒì„± ì‹¤íŒ¨ - ëŒ€ì²´ ë°©ë²• ì‹œë„")
                return self.fallback_prediction()
                
        except Exception as e:
            print(f"ì˜ˆì¸¡ ìƒì„± ì˜¤ë¥˜: {e}")
            return self.fallback_prediction()
    
    def fallback_prediction(self):
        """ë¹ ë¥¸ ëŒ€ì²´ ì˜ˆì¸¡"""
        print("â†’ ë¹ ë¥¸ ëŒ€ì²´ ì˜ˆì¸¡ ì‹¤í–‰")
        
        try:
            from sklearn.ensemble import RandomForestClassifier
            from sklearn.preprocessing import LabelEncoder
            
            train_df = pd.read_csv('train.csv')
            test_df = pd.read_csv('test.csv')
            
            # ê¸°ë³¸ í”¼ì²˜ë§Œ ì‚¬ìš©
            numeric_cols = ['age', 'tenure', 'frequent', 'payment_interval', 'contract_length']
            categorical_cols = ['gender', 'subscription_type']
            
            train_processed = train_df.copy()
            test_processed = test_df.copy()
            
            # ë²”ì£¼í˜• ì¸ì½”ë”©
            le = LabelEncoder()
            for col in categorical_cols:
                if col in train_df.columns and col in test_df.columns:
                    combined = pd.concat([train_df[col], test_df[col]])
                    le.fit(combined.fillna('Unknown'))
                    train_processed[col] = le.transform(train_df[col].fillna('Unknown'))
                    test_processed[col] = le.transform(test_df[col].fillna('Unknown'))
            
            # í”¼ì²˜ ì„ íƒ
            feature_cols = numeric_cols + categorical_cols
            feature_cols = [col for col in feature_cols if col in train_processed.columns and col in test_processed.columns]
            
            X = train_processed[feature_cols].fillna(0)
            y = train_processed['support_needs']
            X_test = test_processed[feature_cols].fillna(0)
            
            # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
            class_counts = np.bincount(y)
            total_samples = len(y)
            class_weights = {}
            
            for i, count in enumerate(class_counts):
                if count > 0:
                    class_weights[i] = total_samples / (len(class_counts) * count)
                else:
                    class_weights[i] = 1.0
            
            class_weights[1] *= 1.15
            class_weights[2] *= 1.09
            
            # ë¹ ë¥¸ ëª¨ë¸ í•™ìŠµ
            model = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                min_samples_split=8,
                min_samples_leaf=4,
                max_features=0.8,
                class_weight=class_weights,
                random_state=42,
                n_jobs=1
            )
            
            model.fit(X, y)
            
            # ì˜ˆì¸¡
            pred_proba = model.predict_proba(X_test)
            
            # í´ë˜ìŠ¤ ê· í˜• ì¡°ì •
            class_adjustments = np.array([1.0, 1.05, 1.02])
            adjusted_proba = pred_proba * class_adjustments[np.newaxis, :]
            normalized_proba = adjusted_proba / adjusted_proba.sum(axis=1, keepdims=True)
            
            predictions = np.argmax(normalized_proba, axis=1)
            
            # ì œì¶œ íŒŒì¼
            submission_df = pd.DataFrame({
                'ID': test_processed['ID'],
                'support_needs': predictions.astype(int)
            })
            
            submission_df.to_csv('submission.csv', index=False)
            
            # ë¶„í¬ ì¶œë ¥
            final_counts = submission_df['support_needs'].value_counts().sort_index()
            print("âœ“ ëŒ€ì²´ ì˜ˆì¸¡ ë¶„í¬:")
            for cls in [0, 1, 2]:
                count = final_counts.get(cls, 0)
                pct = count / len(submission_df) * 100
                print(f"  í´ë˜ìŠ¤ {cls}: {count:,}ê°œ ({pct:.1f}%)")
            
            self.results['prediction'] = {
                'submission_shape': submission_df.shape,
                'prediction_counts': final_counts.to_dict(),
                'method': 'fallback_optimized'
            }
            
            print("âœ“ ëŒ€ì²´ ì˜ˆì¸¡ ì™„ë£Œ")
            return True, submission_df
            
        except Exception as e:
            print(f"ëŒ€ì²´ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return False, None
    
    def generate_report(self):
        """ì„±ê³¼ ë³´ê³ ì„œ"""
        print("\n" + "=" * 50)
        print("ìµœì¢… ì„±ê³¼ ë³´ê³ ì„œ")
        print("=" * 50)
        
        try:
            total_time = time.time() - self.start_time if self.start_time else 0
            minutes = int(total_time // 60)
            seconds = int(total_time % 60)
            print(f"ì´ ì‹¤í–‰ ì‹œê°„: {minutes}ë¶„ {seconds}ì´ˆ")
            
            # ë°ì´í„° ì•ˆì „ì„± ì ê²€ ê²°ê³¼
            print("\nğŸ“Š ë°ì´í„° ì•ˆì „ì„±:")
            if 'data_analysis' in self.results:
                da = self.results['data_analysis']
                
                temporal = da.get('temporal', {})
                if temporal:
                    safe_ratio = temporal.get('safe_ratio', 0)
                    is_safe = temporal.get('is_temporally_safe', False)
                    if is_safe:
                        print(f"  âœ“ ì‹œê°„ì  ëˆ„ìˆ˜: ì•ˆì „ ({safe_ratio:.1%})")
                    else:
                        print(f"  âš  ì‹œê°„ì  ëˆ„ìˆ˜: ë³´ì • ì ìš© ({safe_ratio:.1%})")
                
                leakage = da.get('leakage', {})
                if 'after_interaction' in leakage:
                    print("  âœ“ í”¼ì²˜ ëˆ„ìˆ˜: ì™„ì „ ì œê±° ì²˜ë¦¬")
                
                integrity = da.get('integrity', {})
                if integrity.get('passed', True):
                    print("  âœ“ ë°ì´í„° ë¬´ê²°ì„±: í†µê³¼")
            
            # í”¼ì²˜ ìƒì„± ê²°ê³¼
            print("\nğŸ”§ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§:")
            if 'feature_engineering' in self.results:
                fe = self.results['feature_engineering']
                print(f"  í”¼ì²˜ í™•ì¥: {fe['original_features']} â†’ {fe['final_features']} (+{fe['created_features']})")
                print("  âœ“ ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ ì™„ë£Œ")
            
            # ì „ì²˜ë¦¬ ê²°ê³¼
            print("\nâš™ï¸ ë°ì´í„° ì „ì²˜ë¦¬:")
            if 'preprocessing' in self.results:
                pp = self.results['preprocessing']
                print(f"  ìµœì¢… í”¼ì²˜: {pp.get('selected_features', 0)}ê°œ")
                print(f"  í›ˆë ¨ ë°ì´í„°: {pp.get('train_shape', (0,0))[0]:,}ê°œ")
                print("  âœ“ ì‹œê°„ì  ì•ˆì „ ë¶„í•  ì ìš©")
            
            # ê²€ì¦ ê²°ê³¼
            print("\nğŸ¯ ëª¨ë¸ ê²€ì¦:")
            if 'validation' in self.results:
                val = self.results['validation']
                overall_score = val.get('overall_score', 0.0)
                print(f"  ê²€ì¦ ì ìˆ˜: {overall_score:.4f}")
                
                if overall_score >= self.target_accuracy:
                    print("  âœ“ ëª©í‘œ ì •í™•ë„ ë‹¬ì„±")
                else:
                    gap = self.target_accuracy - overall_score
                    print(f"  â†’ ëª©í‘œê¹Œì§€: {gap:.4f}")
            
            # ëª¨ë¸ í•™ìŠµ ê²°ê³¼
            print("\nğŸ¤– ëª¨ë¸ í•™ìŠµ:")
            if 'model_training' in self.results:
                mt = self.results['model_training']
                successful = mt.get('successful_models', 0)
                print(f"  í•™ìŠµ ì„±ê³µ: {successful}ê°œ ëª¨ë¸")
                print(f"  ìµœê³  ì„±ëŠ¥: {mt['best_validation_score']:.4f}")
                
                if mt.get('best_model'):
                    print(f"  ìµœê³  ëª¨ë¸: {mt['best_model']}")
                
                if mt['target_achieved']:
                    print("  âœ“ ëª©í‘œ ë‹¬ì„±")
            
            # ì˜ˆì¸¡ ê²°ê³¼
            print("\nğŸ“ˆ ì˜ˆì¸¡ ê²°ê³¼:")
            if 'prediction' in self.results:
                pred = self.results['prediction']
                print("  ì˜ˆì¸¡ ë¶„í¬:")
                total_predictions = sum(pred['prediction_counts'].values())
                for cls in [0, 1, 2]:
                    count = pred['prediction_counts'].get(cls, 0)
                    pct = count / total_predictions * 100 if total_predictions > 0 else 0
                    print(f"    í´ë˜ìŠ¤ {cls}: {pct:.1f}%")
                
                method = pred.get('method', 'unknown')
                print(f"  ì˜ˆì¸¡ ë°©ë²•: {method}")
            
            # ì „ì²´ ì„±ê³µë¥ 
            print("\nğŸ“‹ ì‹œìŠ¤í…œ ìƒíƒœ:")
            completed_steps = sum(1 for step in ['data_analysis', 'feature_engineering', 'preprocessing', 'validation', 'model_training', 'prediction'] if step in self.results)
            success_rate = completed_steps / 6 * 100
            
            print(f"  ë‹¨ê³„ ì™„ë£Œìœ¨: {completed_steps}/6 ({success_rate:.1f}%)")
            
            # ì „ì²´ í‰ê°€
            print("\nğŸ–ï¸ ìµœì¢… í‰ê°€:")
            if success_rate >= 100:
                grade = "ì™„ë£Œ"
                icon = "ğŸ‰"
            elif success_rate >= 83:
                grade = "ì„±ê³µ"
                icon = "âœ…"
            else:
                grade = "ë¶€ë¶„ ì™„ë£Œ"
                icon = "âš¡"
                
            print(f"  {icon} ì‹œìŠ¤í…œ ë“±ê¸‰: {grade}")
            print("  ğŸ›¡ï¸ ë°ì´í„° ì•ˆì „ì¥ì¹˜ ì ìš© ì™„ë£Œ")
            
        except Exception as e:
            print(f"ë³´ê³ ì„œ ìƒì„± ì˜¤ë¥˜: {e}")
    
    def run_system(self):
        """ì‹œìŠ¤í…œ ì‹¤í–‰"""
        try:
            # í™˜ê²½ ì„¤ì •
            if not self.setup_environment():
                print("í™˜ê²½ ì„¤ì • ì‹¤íŒ¨")
                return False
            
            # 1ë‹¨ê³„: ë°ì´í„° ë¶„ì„
            success, analyzer = self.step1_data_analysis()
            if not success:
                print("1ë‹¨ê³„ ê²½ê³  - ê³„ì† ì§„í–‰")
            
            # 2ë‹¨ê³„: í”¼ì²˜ ìƒì„±
            success, engineer, train_df, test_df = self.step2_feature_engineering()
            if not success or train_df is None or test_df is None:
                print("2ë‹¨ê³„ ì‹¤íŒ¨ - ëŒ€ì²´ ì˜ˆì¸¡")
                fallback_success, fallback_result = self.fallback_prediction()
                if fallback_success:
                    self.generate_report()
                    return True
                else:
                    print("ëŒ€ì²´ ì˜ˆì¸¡ ì‹¤íŒ¨")
                    return False
            
            # 3ë‹¨ê³„: ì „ì²˜ë¦¬
            success, preprocessor, X_train, X_val, y_train, y_val, X_test, test_ids = self.step3_preprocessing(train_df, test_df)
            if not success or any(data is None for data in [X_train, X_val, y_train, y_val]):
                print("3ë‹¨ê³„ ì‹¤íŒ¨ - ëŒ€ì²´ ì˜ˆì¸¡")
                fallback_success, fallback_result = self.fallback_prediction()
                if fallback_success:
                    self.generate_report()
                    return True
                else:
                    print("ëŒ€ì²´ ì˜ˆì¸¡ ì‹¤íŒ¨")
                    return False
            
            # 4ë‹¨ê³„: ê²€ì¦
            success, validator = self.step4_validation(X_train, y_train, X_val, y_val)
            if not success:
                print("4ë‹¨ê³„ ê²½ê³  - ê³„ì† ì§„í–‰")
            
            # 5ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ
            success, trainer = self.step5_model_training(X_train, X_val, y_train, y_val, engineer, preprocessor)
            if not success:
                print("5ë‹¨ê³„ ì‹¤íŒ¨ - ê³„ì† ì§„í–‰")
            
            # 6ë‹¨ê³„: ì˜ˆì¸¡ ìƒì„±
            success, submission_df = self.step6_prediction()
            if not success:
                print("6ë‹¨ê³„ ì‹¤íŒ¨ - ìµœì¢… ëŒ€ì²´")
                final_success, final_result = self.fallback_prediction()
                if not final_success:
                    print("ìµœì¢… ëŒ€ì²´ ì‹¤íŒ¨")
                    return False
            
            # ë³´ê³ ì„œ ìƒì„±
            self.generate_report()
            
            print(f"\n{'='*50}")
            print("ğŸ‰ ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ")
            print(f"{'='*50}")
            return True
            
        except Exception as e:
            print(f"ì‹œìŠ¤í…œ ì‹¤í–‰ ì˜ˆì™¸: {e}")
            
            try:
                fallback_success, fallback_result = self.fallback_prediction()
                if fallback_success:
                    print("ê¸´ê¸‰ ëŒ€ì²´ ëª¨ë“œ ì„±ê³µ")
                    return True
                else:
                    print("ê¸´ê¸‰ ëŒ€ì²´ ëª¨ë“œ ì‹¤íŒ¨")
                    return False
            except Exception as fallback_e:
                print(f"ê¸´ê¸‰ ëŒ€ì²´ ëª¨ë“œ ì˜ˆì™¸: {fallback_e}")
                return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    ai_system = AISystem()
    
    try:
        success = ai_system.run_system()
        
        if success:
            print("\nâœ… í”„ë¡œê·¸ë¨ ì •ìƒ ì™„ë£Œ")
            return 0
        else:
            print("\nâŒ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì‹¤íŒ¨")
            return 1
            
    except Exception as e:
        print(f"\në©”ì¸ í•¨ìˆ˜ ì˜ˆì™¸: {e}")
        print("âŒ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì‹¤íŒ¨")
        return 1

if __name__ == "__main__":
    exit_code = main()